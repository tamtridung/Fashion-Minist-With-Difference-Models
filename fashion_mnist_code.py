# -*- coding: utf-8 -*-
"""Fashion_MNIST_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DH75IT97ta5BTGaJ2Fr3bpETUfNHIF5R

# Fashion MNIST

[Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) can be used as drop-in replacement for the original MNIST dataset (10 categories of handwritten digits). It shares the same image size (28x28) and structure of training (60,000) and testing (10,000) splits. The class labels are:

| Label|	Description|
|-|-|
|0|	T-shirt/top|
|1|	Trouser|
|2|	Pullover|
|3|	Dress|
|4|	Coat|
|5|	Sandal|
|6|	Shirt|
|7|	Sneaker|
|8|	Bag|
|9|	Ankle boot|

**Example**

<img src="https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png" width="50%"/>

In this notebook, you need to train a classical ML model (no deep learning) to reach the highest accruracy score. Please follow the ML project checklist and make sure you organize your code well.

- **Expected Accuracy Score on the given test set**: >89%
- **Expected Accuracy Score on the HIDDEN test set**: as high as possible. Top 5 will be picked to present

**Submission:** 
- Share your notebook to instructors (quan.tran@coderschool.vn), and prepare your presentation on the next Monday afternoon. 

- The submission.csv file. You can put them inside the submissions folder.
The name of the file should be like this: \<your_name\>_submission.csv. For example: quantran_submission.csv


**Extra optional requirements**:
- Tuning your hyperparameters with both RandomSearch and GridSearch
- Use Sklearn Pipeline 
- Confusion Matrix
- Plot the images that the model predicts incorrectly
- Use confusion matrix and images plotted incorrectly to do error analysis

Get fashion MNIST data
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import joblib 
# %matplotlib inline

import warnings
warnings.filterwarnings('ignore')

sns.set_style("whitegrid")

from tensorflow.keras.datasets import fashion_mnist

(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()

print('Training data:', X_train.shape, y_train.shape)
print('Test data:', X_test.shape, y_test.shape)

plt.imshow(X_train[3], cmap='gray')

def plot_images(images, lbl_true=None, lbl_wrong=None):
  '''Plot images with their labels. Ten each row'''
  plt.figure(figsize=(20,20))
  columns = 10
  for i, image in enumerate(images):
    ax = plt.subplot(len(images) / columns + 1, columns, i + 1)
    
    label_true_w = pd.Series(lbl_true).map(lambda x: classes[x])
    label_pred_w = pd.Series(lbl_wrong).map(lambda x: classes[x])
        
    if not lbl_true is None:
        try:
            ax.set_title(f"T: {label_true_w[i]}\n P: {label_pred_w[i]}", fontsize=16)
        except Exception:
            ax.set_title(f"T: {label_true_w[i]}", fontsize=16)
    
    plt.axis('off')
    plt.subplots_adjust(bottom=0.1)
    plt.imshow(image, cmap='gray')

def get_samples(n_samples, X, y=None):
  '''Get n_samples randomly'''
  samples_index = np.random.choice(np.arange(len(X)), n_samples, replace=False)
  if not y is None:
    return X[samples_index], y[samples_index]
  return X[samples_index]

images, labels = get_samples(30, X_train, y_train)
plot_images(images, labels)

"""These are numpy arrays:
- X_train 
- y_train 
- X_test 
- y_test
"""

print('Trainingm data:', X_train.shape, y_train.shape)
print('Test data:', X_test.shape, y_test.shape)

"""# Test set

Here is the test set without label (FMNIST_augmented_test.npy). You will use your trained machine learning model to make predictions on this test set, and then submit a csv file containing the predictions 
"""

from google.colab import drive
drive.mount('/content/gdrive')

PATH = ''

X_test_augmented = np.load(PATH + 'FMNIST_augmented_test.npy')

X_test_augmented.shape

images = get_samples(10, X_test_augmented)
plot_images(images)

"""Note: **pay a close attention to this test set**. 

This test set is slightly different from the train set. In order to improve your model, **make sure you know what the difference is so that you can perform appropriate processings**.

---

#MODELS
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import joblib 
# %matplotlib inline
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score, KFold
from sklearn.metrics import accuracy_score, classification_report
from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier


from tensorflow.keras.datasets import fashion_mnist
(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()

classes = {0: 'T-shirt/top',
            1: 'Trouser',
            2: 'Pullover',
            3: 'Dress',
            4: 'Coat',
            5: 'Sandal',
            6: 'Shirt',
            7: 'Sneaker',
            8: 'Bag',
            9: 'Ankle boot'}



import warnings
warnings.filterwarnings('ignore')

sns.set_style("whitegrid")

# Evaluate function:
def evaluate(estimator, X, y,cross_val_score=None, on='train'):
    y_pred = estimator.predict(X)
    
    if not cross_val_score is None:
        print(f'mean accuracy on {on} set: ', cross_val_score.mean(), '\n')
    else:
        print(f'accuracy on {on} set: ', accuracy_score(y, y_pred), '\n')
    
    print(classification_report(y, y_pred))
    
    # Confusion_matrix:
    con_matrix = pd.crosstab(pd.Series(y, name='Actual' ),pd.Series(y_pred, name='Predicted'))
    plt.figure(figsize = (9,6))
    plt.title("Confusion Matrix")
    sns.heatmap(con_matrix, cmap="Blues", annot=True, fmt='g')

    return y_pred

# Plot image:
def plot_images(images, lbl_true=None, lbl_wrong=None):
  '''Plot images with their labels. Ten each row'''
  plt.figure(figsize=(20,20))
  columns = 10
  for i, image in enumerate(images):
    ax = plt.subplot(len(images) / columns + 1, columns, i + 1)
    
    label_true_w = pd.Series(lbl_true).map(lambda x: classes[x])
    label_pred_w = pd.Series(lbl_wrong).map(lambda x: classes[x])
        
    if not lbl_true is None:
        try:
            ax.set_title(f"T: {label_true_w[i]}\n P: {label_pred_w[i]}", fontsize=16)
        except Exception:
            ax.set_title(f"T: {label_true_w[i]}", fontsize=16)
    
    plt.axis('off')
    plt.subplots_adjust(bottom=0.1)
    plt.imshow(image, cmap='gray')

# load data:
# X_train_pca = joblib.load('X_train_pca_100')
# X_test_pca = joblib.load('X_test_pca_100')
# y_train = joblib.load('y_train')
# y_test = joblib.load('y_test')
# X_train_fl = joblib.load('X_train_fl')
# X_test_fl = joblib.load('X_test_fl')

# # Get sample:
# pct_sample = 0.1

# X_train_pca_sp, X_not_used, y_train_sp, y_not_used = train_test_split(X_train_pca, y_train, 
#                                                                 test_size=(1-pct_sample), 
#                                                                 stratify=y_train,
#                                                                 )

# # Best Xgboost:
# xgfn = XGBClassifier(learning_rate =0.3,
#                      n_estimators=120,
#                      max_depth=7,
#                      min_child_weight=1,
#                      gamma=0,
#                      subsample=0.8,
#                     n_jobs= -1)

"""## Normalize and reshape data:"""

# Reshape data into 2D DataFrame 
X_train_rs = X_train.reshape((X_train.shape[0],-1))
X_test_rs = X_test.reshape((X_test.shape[0],-1))

X_train_rs.shape, X_test_rs.shape

# check min max
(X_train_rs.min(), X_train_rs.max()),(X_test_rs.min(), X_test_rs.max())

# Nomalize data by using MinmaxScaler
from sklearn.preprocessing import MinMaxScaler

X_train_fl = MinMaxScaler().fit_transform(X_train_rs)
X_test_fl = MinMaxScaler().fit_transform(X_test_rs)

# Check min_max after normalize:
(X_train_fl.min(), X_train_fl.max()),(X_test_fl.min(), X_test_fl.max())

"""## PCA"""

from sklearn.decomposition import PCA

X_train_fl.shape, y_train.shape

# Plot PCA
sns.set_style('whitegrid')

plt.figure(figsize=(16, 9))
pca = PCA().fit(X_train_fl)
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('number of components')
plt.ylabel('cumulative explained variance')

# Variance ratio with 100 components:
pca.explained_variance_ratio_[:100].sum()

"""To saving time when training and predicting, we can use data set after PCA with 100 components which have presented ~91.2% of the total variance, for training model."""

pd.DataFrame(pca.explained_variance_ratio_).plot(kind='bar', figsize=(16,7))
plt.title('variance ratio distribution')
plt.xlim(0,100)
plt.show()

# in put 
def pca_set(X_train_fl, X_test_fl, n_components):
    pca_used = PCA(n_components=n_components)

    # Trainsform data set:
    X_train_pca = pca_used.fit_transform(X_train_fl)
    X_test_pca = pca_used.transform(X_test_fl)
    
    # saving pca:
    joblib.dump(X_train_pca, f'X_train_pca_{pca_used.n_components_}')
    joblib.dump(X_test_pca, f'X_test_pca_{pca_used.n_components_}')    
    
    print(f'DONE === with n_components: {pca_used.n_components_}')
    
    return X_train_pca, X_test_pca

X_train_pca, X_test_pca = pca_set(X_train_fl, X_test_fl, 100)

import plotly.express as px

fig = px.scatter_3d(X_train_pca, x=X_train_pca[:,0], y=X_train_pca[:,1], z=X_train_pca[:,2],
                    color=y_train)

fig.show()

X_train_pca.shape, X_test_pca.shape

"""## Model evaluation:"""

model_results = {}
def save_results(model_name, train_set, test_set):
    model_results[model_name] = []
    model_results[model_name].append(train_set)
    model_results[model_name].append(test_set)
    return model_results



"""### Logistic Regression"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score, KFold
from sklearn.metrics import accuracy_score, classification_report

lr = LogisticRegression()

cvs = cross_val_score(lr, X_train_pca, y_train,
                      scoring='accuracy',
                      cv=KFold(5,True, 96),
                      n_jobs=-1, verbose=1)

# Mean score of accuracy:
cvs.mean()

lr.fit(X_train_pca, y_train)

evaluate(lr, X_train_pca, y_train, cvs, on='train')

evaluate(lr, X_test_pca, y_test,on='test')

save_results('LogisticRegression', 0.8508, 0.8407)

"""### XGboost:"""

from xgboost import XGBClassifier

"""#### Find the best learning rate:

Learning rate can makes the model more robust by shrinking the weights on each step
Typical final values to be used: 0.01-0.2

In this case i will use learning_rate = [0.001, 0.01, 0.1, 0.5, 1] to train data
"""

xgb1 = XGBClassifier(learning_rate =0.1,
                     n_estimators=100,
                     max_depth=5,
                     min_child_weight=1,
                     gamma=0,
                     subsample=0.8)

params = {'learning_rate': [0.01,0.1,0.3,0.5,1]}

gs1 = GridSearchCV(xgb1, params,
                   scoring = 'accuracy', cv=5, n_jobs=-1,
                   verbose=1)

gs1.fit(X_train_pca_sp, y_train_sp)

gs1.best_score_

pd.DataFrame(gs1.cv_results_)

"""We can see that the difference in accuracy between the learning rates is not much. So we can choose learning rate = 0.3    """

best_model = gs1.best_estimator_

# train model with full data:
best_model.fit(X_train_pca, y_train)

evaluate(best_model, X_test_pca, y_test, on='test')

"""#### Using learing_rate = 0.3, tune n_estimators, max_depth, min_child_weight:"""

params = {'learning_rate': [0.3],
         'n_estimators': range(50,170,20),
         'max_depth': range(3, 10, 2),
         'min_child_weight':range(1,6,2)}

rd_search = RandomizedSearchCV(xgb1, params,n_iter=10,
                           scoring = 'accuracy', cv=5, n_jobs=-1,
                           verbose=1)

rd_search.fit(X_train_pca_sp, y_train_sp)

rd_search.best_score_

pd.DataFrame(rd_search.cv_results_)

rd_search.best_params_

"""sau khi khảo sát, ta có thể tunning các hyper params cho bước tiếp theo như sau:

    n_estimators: 110,120,130
    min_child_weight : 1,2
    max_depth: 6,7,8,9

#### Using learing_rate = 0.3, tune n_estimators, max_depth, min_child_weight 2
"""

params = {'learning_rate': [0.3],
         'n_estimators': [110,120,130],
         'max_depth': [6,7,8,9],
         'min_child_weight':[1,2]}

gr_search = GridSearchCV(xgb1, params,
                           scoring = 'accuracy', cv=5, n_jobs=-1,
                           verbose=1)

gr_search.fit(X_train_pca_sp, y_train_sp)

gr_search.best_score_

pd.DataFrame(gr_search.cv_results_)

gr_search.best_params_

"""#### Run again with best params in all data set without pca"""

xgfn = XGBClassifier(learning_rate =0.3,
                     n_estimators=120,
                     max_depth=7,
                     min_child_weight=1,
                     gamma=0,
                     subsample=0.8,
                    n_jobs= -1)

xgfn.fit(X_train_fl, y_train)

# joblib.dump(xgfn, 'Xgboost_final')

xgfn = joblib.load('Xgboost_final')

xgfn.get_params

evaluate(xgfn, X_train_fl, y_train, on='train')

evaluate(xgfn, X_test_fl, y_test, on='test')

save_results('XGBoost without PCA', 1, 0.8979)

"""#### Xgboost with best paras with dataset pca = 100"""

X_train_pca.shape, X_test_pca.shape

xgfn.fit(X_train_pca, y_train)

# joblib.dump(xgfn, 'Xgboost_final_trained_pca_100')

# xgfn = joblib.load('Xgboost_final_trained_pca_113')

evaluate(xgfn, X_train_pca, y_train, on='train')

evaluate(xgfn, X_test_pca, y_test, on='test')

save_results('XGBoost PCA 100', 1, 0.8825)

"""#### Xgboost with best paras and pca = 350"""

X_train_pca_350 = joblib.load('X_train_pca_350')
X_test_pca_350 = joblib.load('X_test_pca_350')

X_train_pca_350.shape, X_test_pca_350.shape

xgfn.fit(X_train_pca_350, y_train)

# joblib.dump(xgfn, 'Xgboost_final_trained_pca_350')

evaluate(xgfn, X_train_pca_350, y_train)

evaluate(xgfn, X_test_pca_350, y_test)

xgfn.get_params

save_results('XGBoost PCA 350', 1, 0.5513)

"""#### Xgboost with best paras and pca = 40"""

X_train_pca_40, X_test_pca_40 = pca_set(X_train_fl, X_test_fl, 40)
X_train_pca_40.shape, X_test_pca_40.shape

xgfn.fit(X_train_pca_40, y_train)

# joblib.dump(xgfn, 'Xgboost_final_trained_pca_40')

evaluate(xgfn, X_train_pca_40, y_train)

evaluate(xgfn, X_test_pca_40, y_test, on='test')

save_results('XGBoost PCA 40', 0.999, 0.8726)

"""### KNN"""

from sklearn.neighbors import KNeighborsClassifier
k = KNeighborsClassifier()

param_grid = {'n_neighbors': np.arange(1,10), 
              'weights': ['uniform', 'distance'],
              'leaf_size': [30,40,50]}

knn_model = RandomizedSearchCV(k, param_grid, n_iter=30,
                                scoring='accuracy',
                                n_jobs= -1,
                                cv=5,
                                verbose=1)

knn_model.fit(X_train_sp, y_train_sp)

print("tuned hpyerparameters :(best parameters) ",knn_model.best_params_)

# caculate the predictions
train_predictions_label = knn_model.predict(X_train_sp)

test_predictions_label = knn_model.predict(X_test_fl)

#get the score of train set 
accuracy_score(y_train_sp, train_predictions_label)

# and test set 
accuracy_score(y_test, test_predictions_label)

save_results('KNN', 1, 0.832)

"""### Decision tree

"""

from sklearn.tree import DecisionTreeClassifier
trees = DecisionTreeClassifier()
param_grid1 = {'max_depth': np.arange(5,30), 
              'min_samples_leaf': np.arange(1,300)
             }
tree_model =  RandomizedSearchCV(trees, param_grid1, n_iter=30,
                                scoring='accuracy',
                                n_jobs= -1,
                                cv=5,
                                verbose=1)

tree_model.fit(X_train_sp,y_train_sp)

print("tuned hpyerparameters :(best parameters) ",tree_model.best_params_)

# caculate the predictions
train_predictions_label = tree_model.predict(X_train_sp)

test_predictions_label = tree_model.predict(X_test_fl)

#get the score of train set 
from sklearn.metrics import accuracy_score
accuracy_score(y_train_sp, train_predictions_label)

# and test set 
accuracy_score(y_test, test_predictions_label)

save_results('Decision Tree', 0.8567, 0.785)

"""### AdaBoost"""

import numpy as np

from sklearn.ensemble import AdaBoostClassifier
ada = AdaBoostClassifier()
param_grid2 = {'n_estimators':[50,60,70,80], 
              'learning_rate': np.arange(1,10)
             }
ada_model =  RandomizedSearchCV(ada, param_grid2, n_iter=30,
                                scoring='accuracy',
                                n_jobs= -1,
                                cv=5,
                                verbose=1)

ada_model.fit(X_train_sp,y_train_sp)

print("tuned hpyerparameters :(best parameters) ",ada_model.best_params_)

# caculate the predictions
train_predictions_label = ada_model.predict(X_train_sp)

test_predictions_label = ada_model.predict(X_test_fl)

#get the score of train set
>>> from sklearn.metrics import accuracy_score
accuracy_score(y_train_sp, train_predictions_label)

#  and test set
accuracy_score(y_test, test_predictions_label)

save_results('AdaBoost', 0.410, 0.404)

"""### RandomForest"""

rf = RandomForestClassifier(n_estimators=100, max_depth=50, random_state=42)
rf.fit(X_pca, y_train)

eval(rf, X_test_pca, y_test,on='test')

save_results('RandomForest', 1, 0.8614)

c_range = np.logspace(-4,1.2, 30, endpoint=True)
c_range

"""### SVC"""

svc = SVC(C=13,kernel='rbf',gamma="auto",probability = True)
svc.fit(X_train_pca,y_train)

# Evaluate in train set:
evaluate(svc, X_train_pca, y_train)

# Evaluate in test set:
evaluate(svc, X_test_pca, y_test)

save_results('SVC', 0.94326, 0.8955)

"""## Models comparition"""

models = pd.DataFrame(model_results).T.reset_index()
models.columns = ['Model','Train set', 'Test set']

models

models.plot(kind='bar', x = 'Model', figsize=(16,7))

for i in range(len(models)):
    # train label:
    plt.text(i-0.25,models['Train set'][i]+0.01 , round(models['Train set'][i],2))

    # test label:
    plt.text(i+0.05,models['Test set'][i]+0.01 , round(models['Test set'][i],2))

plt.ylim(0,1.1)
plt.title('Model result comparition')
plt.grid(ls='-.', c='pink')
plt.xticks(rotation=60)

i=1
plt.text(i+0.1,models['Test set'][i]+0.05 , '️*')
i=9
plt.text(i+0.1,models['Test set'][i]+0.05 , '️*')

plt.show()

"""- XGBoost(without be treated by PCA) and SVC(be treated by PCA with n_components=100) give the highest results in accuracy on test set.

- To save training time as well as make better predictions for noisy data, we decided to use SVC

## Pipeline
"""

from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline

class preprocessing(BaseEstimator, TransformerMixin):
    def __init__(self, input_c):
        self.components = input_c
        pass
    def fit(self, X, y=None):
        return self  # nothing else to do
    def transform(self, X):
        # reshape
        X = X.reshape((X.shape[0],-1))

        # Nomalize
        X = MinMaxScaler().fit_transform(X)
        
        #pca
        pca = PCA(n_components=self.components)
        pca.fit(X)
        X = pca.transform(X)

        return X


final_pipe = Pipeline([ ('transform',preprocessing(100)),
                        ('model', SVC(C=13,kernel='rbf',gamma="auto",probability = True))])

X_train_pca.shape, X_test_pca.shape

final_pipe.fit(X_train, y_train)

"""## Analysis result - using result of SVC"""

y_train_pred = evaluate(final_pipe, X_train, y_train)

# Evaluate in test set:
y_test_pred = evaluate(final_pipe, X_test, y_test, on='test')

"""- Class 6 (Shirt) makes the model the most difficult to predict
- Model is most confused between class 6 (shirt) vs class 0 (T-shirt/top)
- In addition, the model also confused quite a lot between class pairs such as: 2 (Pullover) - 4 (Coat) - 6 (Shirt)

"""

from ipywidgets import interact, interactive, fixed, interact_manual
import ipywidgets as widgets
from IPython.display import display

classes_name = [f'{i}: {classes[i]}'for i in classes.keys()]
print(classes_name)

def plot_images_2( class_code=0):
    no_img = 50
    condition = (y_train!=y_train_pred) & (y_train==class_code)

    wrong_pred_imgs = X_train[condition]
    label_true = y_train[condition]
    label_pred = y_train_pred[condition]

    plot_images(wrong_pred_imgs[:no_img], label_true[:no_img], label_pred[:no_img])

    
classes_name = [f'{i}: {classes[i]}'for i in classes.keys()]
drop_down = widgets.Dropdown(options = classes.keys(),  description = 'select class:')


widgets.interact(plot_images_2, class_code=drop_down)